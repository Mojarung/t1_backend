"""
–°–µ—Ä–≤–∏—Å –¥–ª—è HR-–ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
–†–µ–∞–ª–∏–∑—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º —É–º–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ RAG-–º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
"""

import json
import re
import httpx
import time
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import and_, or_, func

from app.config import settings
from app.models import User, Vec_profile, UserRole
from app.schemas import CandidateSearchRequest, CandidateSearchResponse, CandidateMatch

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏ LangChain
import numpy as np
from pgvector.sqlalchemy import Vector


class HRCandidateSearchService:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
    
    –ê–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã:
    1. –ü—Ä–∏–º–µ–Ω—è–µ—Ç –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –Ω–∞–≤—ã–∫–∞–º –∏ –æ–ø—ã—Ç—É
    2. –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ - –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
    3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
    4. –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø—Ä–æ—Ñ–∏–ª—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    5. LLM –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∞–º–º–∞—Ä–∏
    6. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
    """

    def __init__(self):
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Scibox)
        self.provider = "scibox"
        self.embedding_dimension = 1024  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤ bge-m3

    def _build_llm_request(self, prompt: str, is_embedding: bool = False) -> tuple[str, Dict[str, str], Dict[str, Any]]:
        """
        –°–æ–∑–¥–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM API (Scibox).
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ chat completion, —Ç–∞–∫ –∏ embeddings endpoints.
        """
        system_prompt = (
            "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π HR-—ç–∫—Å–ø–µ—Ä—Ç —Å –æ–ø—ã—Ç–æ–º –ø–æ–¥–±–æ—Ä–∞ IT-–ø–µ—Ä—Å–æ–Ω–∞–ª–∞. "
            "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ—Ñ–∏–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ, —É—á–∏—Ç—ã–≤–∞—è "
            "–∏—Ö –Ω–∞–≤—ã–∫–∏, –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è."
        )

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è Scibox API
        base_url = getattr(settings, 'scibox_base_url', 'https://llm.t1v.scibox.tech/v1')
        api_key = getattr(settings, 'scibox_api_key', 'sk-your-api-key-here')
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        if is_embedding:
            # –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            url = f"{base_url.rstrip('/')}/embeddings"
            payload = {
                "model": "bge-m3",  # Embedding –º–æ–¥–µ–ª—å
                "input": prompt
            }
        else:
            # –ó–∞–ø—Ä–æ—Å –¥–ª—è chat completion
            url = f"{base_url.rstrip('/')}/chat/completions"
            payload = {
                "model": getattr(settings, 'scibox_model', 'Qwen2.5-72B-Instruct-AWQ'),
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt},
                ],
                "max_tokens": 1000,
                "temperature": 0.3,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                "top_p": 0.9,
            }
        
        return url, headers, payload

    async def _call_llm(self, prompt: str, is_embedding: bool = False) -> Any:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM API
        """
        url, headers, payload = self._build_llm_request(prompt, is_embedding)

        print(f"ü§ñ LLM Request: {self.provider}")
        print(f"üìç URL: {url}")
        print(f"üìä Type: {'Embedding' if is_embedding else 'Chat Completion'}")

        async with httpx.AsyncClient(timeout=120.0) as client:
            try:
                response = await client.post(url, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                
                if is_embedding:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
                    return data["data"][0]["embedding"]
                else:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                    return data["choices"][0]["message"]["content"]
                    
            except httpx.HTTPStatusError as e:
                print(f"‚ùå HTTP Error: {e.response.status_code} - {e.response.text}")
                raise Exception(f"LLM API Error: {e.response.status_code}")
            except Exception as e:
                print(f"‚ùå Request Error: {e}")
                raise Exception(f"LLM Request Failed: {str(e)}")

    async def _generate_job_embedding(self, job_description: str, job_title: str) -> List[float]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        """
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        full_job_context = f"–í–∞–∫–∞–Ω—Å–∏—è: {job_title}\n\n–û–ø–∏—Å–∞–Ω–∏–µ: {job_description}"
        
        try:
            embedding = await self._call_llm(full_job_context, is_embedding=True)
            return embedding
        except Exception as e:
            print(f"‚ùå Failed to generate job embedding: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return [0.0] * self.embedding_dimension

    def _apply_basic_filters(self, db: Session, required_skills: List[str], experience_level: Optional[str]) -> Any:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –Ω–∞–≤—ã–∫–∞–º –∏ –æ–ø—ã—Ç—É —Ä–∞–±–æ—Ç—ã.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç QuerySet –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º.
        """
        query = db.query(User).filter(
            User.role == UserRole.USER,  # –¢–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (–Ω–µ HR)
            User.is_active == True
        )

        # –§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞–≤—ã–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        if required_skills:
            skill_conditions = []
            for skill in required_skills:
                # –ò—â–µ–º –≤ —è–∑—ã–∫–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
                skill_conditions.append(
                    func.json_extract_path_text(User.programming_languages, '$').ilike(f'%{skill}%')
                )
                # –ò—â–µ–º –≤ –ø—Ä–æ—á–∏—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è—Ö
                skill_conditions.append(
                    func.json_extract_path_text(User.other_competencies, '$').ilike(f'%{skill}%')
                )
            
            # –•–æ—Ç—è –±—ã –æ–¥–∏–Ω –Ω–∞–≤—ã–∫ –¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å
            query = query.filter(or_(*skill_conditions))

        # –§–∏–ª—å—Ç—Ä –ø–æ —É—Ä–æ–≤–Ω—é –æ–ø—ã—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if experience_level and experience_level.lower() in ['junior', 'middle', 'senior']:
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã –∏–∑ JSON –ø–æ–ª—è work_experience
            pass

        return query

    def _apply_additional_filters(self, query: Any, additional_keywords: List[str]) -> Any:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã, –µ—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ.
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã –∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏.
        """
        if additional_keywords:
            additional_conditions = []
            for keyword in additional_keywords:
                # –ò—â–µ–º –≤ –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã
                additional_conditions.append(
                    func.json_extract_path_text(User.work_experience, '$').ilike(f'%{keyword}%')
                )
                # –ò—â–µ–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ "–æ —Å–µ–±–µ"
                additional_conditions.append(User.about.ilike(f'%{keyword}%'))
            
            # –•–æ—Ç—è –±—ã –æ–¥–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–ª–æ–≤–∏–µ –¥–æ–ª–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è
            query = query.filter(or_(*additional_conditions))

        return query

    async def _perform_vector_search(self, db: Session, job_embedding: List[float], 
                                   filtered_users: List[User], limit: int = 20) -> List[Tuple[User, float]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Ä–µ–¥–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –∏—Ö similarity scores.
        """
        user_ids = [user.id for user in filtered_users]
        
        # –ó–∞–ø—Ä–æ—Å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π
        vector_results = db.query(Vec_profile, User).join(User).filter(
            Vec_profile.user_id.in_(user_ids)
        ).all()

        candidates_with_similarity = []
        
        for vec_profile, user in vector_results:
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            similarity = self._cosine_similarity(job_embedding, vec_profile.vector)
            candidates_with_similarity.append((user, similarity))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        candidates_with_similarity.sort(key=lambda x: x[1], reverse=True)
        return candidates_with_similarity[:limit]

    def _cosine_similarity(self, vec1: List[float], vec2) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏
        """
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy arrays –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
            a = np.array(vec1)
            b = np.array(vec2)
            
            # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ = dot(a,b) / (||a|| * ||b||)
            dot_product = np.dot(a, b)
            norm_a = np.linalg.norm(a)
            norm_b = np.linalg.norm(b)
            
            if norm_a == 0 or norm_b == 0:
                return 0.0
            
            similarity = dot_product / (norm_a * norm_b)
            return float(similarity)
        except Exception as e:
            print(f"‚ùå Similarity calculation error: {e}")
            return 0.0

    async def _analyze_candidate_with_ai(self, user: User, job_description: str, 
                                       job_title: str, similarity_score: float) -> CandidateMatch:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM.
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∏ —Å–∞–º–º–∞—Ä–∏.
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        candidate_info = f"""
–ö–ê–ù–î–ò–î–ê–¢:
–ò–º—è: {user.full_name or f"{user.first_name or ''} {user.last_name or ''}".strip() or user.username}
Email: {user.email}
–õ–æ–∫–∞—Ü–∏—è: {user.location or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}
–û —Å–µ–±–µ: {user.about or '–ù–µ —É–∫–∞–∑–∞–Ω–æ'}
–ñ–µ–ª–∞–µ–º–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞: {user.desired_salary or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}
–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: {', '.join(user.programming_languages or []) or '–ù–µ —É–∫–∞–∑–∞–Ω—ã'}
–ü—Ä–æ—á–∏–µ –Ω–∞–≤—ã–∫–∏: {', '.join(user.other_competencies or []) or '–ù–µ —É–∫–∞–∑–∞–Ω—ã'}
–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: {len(user.work_experience or []) if user.work_experience else 0} –ø–æ–∑–∏—Ü–∏–π
–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: {len(user.education or []) if user.education else 0} –∑–∞–ø–∏—Å–µ–π
–í–µ–∫—Ç–æ—Ä–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å —Å –≤–∞–∫–∞–Ω—Å–∏–µ–π: {similarity_score:.2f}
        """.strip()

        prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≤–∞–∫–∞–Ω—Å–∏–∏.

–í–ê–ö–ê–ù–°–ò–Ø:
–ù–∞–∑–≤–∞–Ω–∏–µ: {job_title}
–û–ø–∏—Å–∞–Ω–∏–µ: {job_description}

{candidate_info}

–ó–ê–î–ê–ß–ò:
1. –û—Ü–µ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –æ—Ç 0.0 –¥–æ 1.0 (–≥–¥–µ 1.0 - –∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ)
2. –í—ã–¥–µ–ª–∏ 2-3 –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
3. –£–∫–∞–∂–∏ 1-2 –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –Ω–∞–≤—ã–∫–∏
4. –ù–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)

–û–¢–í–ï–¢ –í –§–û–†–ú–ê–¢–ï JSON:
{{
    "match_score": 0.85,
    "strengths": ["–°–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 1", "–°–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 2"],
    "growth_areas": ["–û–±–ª–∞—Å—Ç—å –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è 1", "–û–±–ª–∞—Å—Ç—å –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è 2"],
    "summary": "–ö—Ä–∞—Ç–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –æ–± —ç—Ç–æ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–µ –∏ –µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏"
}}

–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞!
        """

        try:
            ai_response = await self._call_llm(prompt)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_match = re.search(r'\{[\s\S]*\}', ai_response)
            if json_match:
                analysis_data = json.loads(json_match.group())
            else:
                analysis_data = json.loads(ai_response)

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç CandidateMatch
            return CandidateMatch(
                user_id=user.id,
                full_name=user.full_name or f"{user.first_name or ''} {user.last_name or ''}".strip() or user.username,
                email=user.email,
                current_position=self._extract_current_position(user),
                experience_years=self._calculate_experience_years(user),
                key_skills=user.other_competencies or [],
                programming_languages=user.programming_languages or [],
                match_score=analysis_data.get("match_score", 0.5),
                ai_summary=analysis_data.get("summary", "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"),
                strengths=analysis_data.get("strengths", []),
                growth_areas=analysis_data.get("growth_areas", []),
                similarity_score=similarity_score
            )

        except Exception as e:
            print(f"‚ùå AI analysis error for user {user.id}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self._create_fallback_candidate_match(user, similarity_score)

    def _extract_current_position(self, user: User) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—É—â—É—é –ø–æ–∑–∏—Ü–∏—é –∏–∑ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã"""
        if not user.work_experience:
            return None
        
        # –ò—â–µ–º —Ç–µ–∫—É—â—É—é —Ä–∞–±–æ—Ç—É (is_current: true –∏–ª–∏ –Ω–µ—Ç end_date)
        for experience in user.work_experience:
            if isinstance(experience, dict):
                if experience.get('is_current') or not experience.get('period_end'):
                    return experience.get('role') or experience.get('position')
        
        # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é
        if user.work_experience:
            last_exp = user.work_experience[0] if isinstance(user.work_experience[0], dict) else None
            if last_exp:
                return last_exp.get('role') or last_exp.get('position')
        
        return None

    def _calculate_experience_years(self, user: User) -> Optional[str]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–∏–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã –≤ –≥–æ–¥–∞—Ö"""
        if not user.work_experience:
            return None
        
        total_months = 0
        for experience in user.work_experience:
            if isinstance(experience, dict):
                start_date = experience.get('period_start')
                end_date = experience.get('period_end') 
                
                # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞: –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞—Ç—ã, —Å—á–∏—Ç–∞–µ–º —Ä–∞–∑–Ω–æ—Å—Ç—å
                if start_date and end_date:
                    try:
                        # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
                        total_months += 12  # –ó–∞–≥–ª—É—à–∫–∞: —Å—á–∏—Ç–∞–µ–º –≥–æ–¥ –∑–∞ –∫–∞–∂–¥—É—é –ø–æ–∑–∏—Ü–∏—é
                    except:
                        pass
        
        if total_months > 0:
            years = total_months // 12
            return f"{years} –ª–µ—Ç" if years > 1 else f"{total_months} –º–µ—Å."
        
        return "–û–ø—ã—Ç –Ω–µ —É–∫–∞–∑–∞–Ω"

    def _create_fallback_candidate_match(self, user: User, similarity_score: float) -> CandidateMatch:
        """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ AI"""
        base_score = min(0.8, similarity_score + 0.2) if similarity_score > 0.5 else similarity_score
        
        return CandidateMatch(
            user_id=user.id,
            full_name=user.full_name or f"{user.first_name or ''} {user.last_name or ''}".strip() or user.username,
            email=user.email,
            current_position=self._extract_current_position(user),
            experience_years=self._calculate_experience_years(user),
            key_skills=user.other_competencies or [],
            programming_languages=user.programming_languages or [],
            match_score=round(base_score, 2),
            ai_summary="–ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –ø—Ä–æ—Ñ–∏–ª—è",
            strengths=["–ï—Å—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ–ø—ã—Ç"] if similarity_score > 0.6 else [],
            growth_areas=["–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"],
            similarity_score=similarity_score
        )

    async def search_candidates(self, db: Session, request: CandidateSearchRequest) -> CandidateSearchResponse:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.
        –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è -> –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ -> AI –∞–Ω–∞–ª–∏–∑
        """
        start_time = time.time()
        applied_filters = []

        print(f"üîç Starting candidate search for: {request.job_title}")
        
        # –®–∞–≥ 1: –ü—Ä–∏–º–µ–Ω—è–µ–º –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        print("üìã Applying basic filters...")
        base_query = self._apply_basic_filters(db, request.required_skills, request.experience_level)
        base_candidates = base_query.all()
        
        if request.required_skills:
            applied_filters.append(f"Skills: {', '.join(request.required_skills)}")
        if request.experience_level:
            applied_filters.append(f"Experience: {request.experience_level}")
        
        print(f"üìä Found {len(base_candidates)} candidates after basic filtering")

        # –®–∞–≥ 2: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        filtered_candidates = base_candidates
        if len(base_candidates) > request.threshold_filter_limit:
            print(f"‚ö° Too many candidates ({len(base_candidates)}), applying additional filters...")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏
            additional_keywords = self._extract_key_terms(request.job_description)
            additional_query = self._apply_additional_filters(base_query, additional_keywords)
            filtered_candidates = additional_query.all()
            
            applied_filters.append(f"Additional keywords: {', '.join(additional_keywords[:3])}")
            print(f"üìä After additional filtering: {len(filtered_candidates)} candidates")

        # –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        print("üß† Generating job embedding...")
        job_embedding = await self._generate_job_embedding(request.job_description, request.job_title)

        # –®–∞–≥ 4: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Ä–µ–¥–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤  
        print("üîé Performing vector similarity search...")
        candidates_with_similarity = await self._perform_vector_search(
            db, job_embedding, filtered_candidates, request.max_candidates
        )

        # –®–∞–≥ 5: AI-–∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        print(f"ü§ñ Analyzing {len(candidates_with_similarity)} candidates with AI...")
        analyzed_candidates = []
        
        for user, similarity in candidates_with_similarity:
            try:
                candidate_match = await self._analyze_candidate_with_ai(
                    user, request.job_description, request.job_title, similarity
                )
                analyzed_candidates.append(candidate_match)
            except Exception as e:
                print(f"‚ùå Failed to analyze candidate {user.id}: {e}")
                # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
                fallback_match = self._create_fallback_candidate_match(user, similarity)
                analyzed_candidates.append(fallback_match)

        # –®–∞–≥ 6: –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ AI
        analyzed_candidates.sort(key=lambda x: x.match_score, reverse=True)

        processing_time = time.time() - start_time
        print(f"‚úÖ Search completed in {processing_time:.2f}s")

        return CandidateSearchResponse(
            job_title=request.job_title,
            total_profiles_found=len(filtered_candidates),
            processed_by_ai=len(analyzed_candidates),
            filters_applied=applied_filters,
            candidates=analyzed_candidates,
            processing_time_seconds=round(processing_time, 2)
        )

    def _extract_key_terms(self, text: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        key_terms = []
        
        # –û–±—â–∏–µ IT —Ç–µ—Ä–º–∏–Ω—ã
        it_terms = [
            'backend', 'frontend', 'fullstack', 'devops', 'qa', 'analyst', 'manager',
            'mobile', 'web', 'api', 'database', 'cloud', 'docker', 'kubernetes',
            'agile', 'scrum', 'team lead', 'architect', 'senior', 'middle', 'junior'
        ]
        
        text_lower = text.lower()
        for term in it_terms:
            if term in text_lower:
                key_terms.append(term)
        
        return key_terms[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
_hr_search_service = None

def get_hr_candidate_search_service() -> HRCandidateSearchService:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞ –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
    global _hr_search_service
    if _hr_search_service is None:
        _hr_search_service = HRCandidateSearchService()
    return _hr_search_service
