"""
–°–µ—Ä–≤–∏—Å –¥–ª—è HR-–ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
–†–µ–∞–ª–∏–∑—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º —É–º–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ RAG-–º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
"""

import json
import re
import httpx
import time
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import and_, or_, func, String

from app.config import settings
from app.models import User, Vec_profile, UserRole
from app.schemas import CandidateSearchRequest, CandidateSearchResponse, CandidateMatch

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –∏ LangChain
import numpy as np
from pgvector.sqlalchemy import Vector


class HRCandidateSearchService:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
    
    –ê–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã:
    1. –ü—Ä–∏–º–µ–Ω—è–µ—Ç –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –Ω–∞–≤—ã–∫–∞–º –∏ –æ–ø—ã—Ç—É
    2. –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ - –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
    3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
    4. –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø—Ä–æ—Ñ–∏–ª—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    5. LLM –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∞–º–º–∞—Ä–∏
    6. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
    """

    def __init__(self):
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Scibox)
        self.provider = "scibox"
        self.embedding_dimension = 1024  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤ bge-m3

    def _build_llm_request(self, prompt: str, is_embedding: bool = False) -> tuple[str, Dict[str, str], Dict[str, Any]]:
        """
        –°–æ–∑–¥–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM API (Scibox).
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ chat completion, —Ç–∞–∫ –∏ embeddings endpoints.
        """
        system_prompt = (
            "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π HR-—ç–∫—Å–ø–µ—Ä—Ç —Å –æ–ø—ã—Ç–æ–º –ø–æ–¥–±–æ—Ä–∞ IT-–ø–µ—Ä—Å–æ–Ω–∞–ª–∞. "
            "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ—Ñ–∏–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ, —É—á–∏—Ç—ã–≤–∞—è "
            "–∏—Ö –Ω–∞–≤—ã–∫–∏, –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è."
        )

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è Scibox API
        base_url = getattr(settings, 'scibox_embeddings_base_url', 'https://llm.t1v.scibox.tech/v1')
        api_key = getattr(settings, 'scibox_embeddings_api_key', 'sk-your-api-key-here')
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        if is_embedding:
            # –ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            url = f"{base_url.rstrip('/')}/embeddings"
            payload = {
                "model": "bge-m3",  # Embedding –º–æ–¥–µ–ª—å
                "input": prompt
            }
        else:
            # –ó–∞–ø—Ä–æ—Å –¥–ª—è chat completion
            url = f"{settings.scibox_base_url.rstrip('/')}/chat/completions"
            payload = {
                "model": getattr(settings, 'scibox_model', 'Qwen2.5-72B-Instruct-AWQ'),
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt},
                ],
                "max_tokens": 1000,
                "temperature": 0.3,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                "top_p": 0.9,
            }
        
        return url, headers, payload

    async def _call_llm(self, prompt: str, is_embedding: bool = False) -> Any:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ LLM API
        """
        url, headers, payload = self._build_llm_request(prompt, is_embedding)

        print(f"ü§ñ LLM Request: {self.provider}")
        print(f"üìç URL: {url}")
        print(f"üìä Type: {'Embedding' if is_embedding else 'Chat Completion'}")

        async with httpx.AsyncClient(timeout=120.0) as client:
            try:
                response = await client.post(url, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                
                if is_embedding:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
                    return data["data"][0]["embedding"]
                else:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                    return data["choices"][0]["message"]["content"]
                    
            except httpx.HTTPStatusError as e:
                print(f"‚ùå HTTP Error: {e.response.status_code} - {e.response.text}")
                raise Exception(f"LLM API Error: {e.response.status_code}")
            except Exception as e:
                print(f"‚ùå Request Error: {e}")
                raise Exception(f"LLM Request Failed: {str(e)}")

    async def _generate_job_embedding(self, job_description: str, job_title: str) -> List[float]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        """
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        full_job_context = f"–í–∞–∫–∞–Ω—Å–∏—è: {job_title}\n\n–û–ø–∏—Å–∞–Ω–∏–µ: {job_description}"
        
        try:
            embedding = await self._call_llm(full_job_context, is_embedding=True)
            return embedding
        except Exception as e:
            print(f"‚ùå Failed to generate job embedding: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return [0.0] * self.embedding_dimension

    def _apply_basic_filters(self, db: Session, required_skills: List[str], experience_level: Optional[str]) -> Any:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –Ω–∞–≤—ã–∫–∞–º –∏ –æ–ø—ã—Ç—É —Ä–∞–±–æ—Ç—ã.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç QuerySet –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º.
        """
        query = db.query(User).filter(
            User.role == UserRole.USER,  # –¢–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (–Ω–µ HR)
            User.is_active == True
        )

        # –§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞–≤—ã–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        if required_skills and len(required_skills) > 0:
            skill_conditions = []
            for skill in required_skills:
                skill = skill.strip()
                if skill:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–≤—ã–∫ –Ω–µ –ø—É—Å—Ç–æ–π
                    # –ò—â–µ–º –≤ —è–∑—ã–∫–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è (JSON -> —Ç–µ–∫—Å—Ç)
                    skill_conditions.append(
                        User.programming_languages.cast(String).ilike(f'%{skill}%')
                    )
                    # –ò—â–µ–º –≤ –ø—Ä–æ—á–∏—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è—Ö (JSON -> —Ç–µ–∫—Å—Ç)  
                    skill_conditions.append(
                        User.other_competencies.cast(String).ilike(f'%{skill}%')
                    )
                    # –ò—â–µ–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ "–æ —Å–µ–±–µ" (–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç)
                    skill_conditions.append(
                        User.about.ilike(f'%{skill}%')
                    )
            
            if skill_conditions:
                # –•–æ—Ç—è –±—ã –æ–¥–∏–Ω –Ω–∞–≤—ã–∫ –¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å
                query = query.filter(or_(*skill_conditions))

        # –§–∏–ª—å—Ç—Ä –ø–æ —É—Ä–æ–≤–Ω—é –æ–ø—ã—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if experience_level and experience_level.lower() in ['junior', 'middle', 'senior']:
            # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —É—Ä–æ–≤–Ω—è –≤ –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–∏
            experience_conditions = []
            exp_level = experience_level.lower()
            
            # –ò—â–µ–º –≤ JSON –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã (–ø—Ä–∏–≤–æ–¥–∏–º –∫ —Ç–µ–∫—Å—Ç—É)
            experience_conditions.append(
                User.work_experience.cast(String).ilike(f'%{exp_level}%')
            )
            # –ò—â–µ–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ "–æ —Å–µ–±–µ" (–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç)
            experience_conditions.append(
                User.about.ilike(f'%{exp_level}%')
            )
            # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –ø–æ —É—Ä–æ–≤–Ω—é
            if exp_level == 'senior':
                experience_conditions.extend([
                    User.about.ilike('%senior%'),
                    User.about.ilike('%lead%'),
                    User.about.ilike('%–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä%'),
                    User.work_experience.cast(String).ilike('%senior%'),
                    User.work_experience.cast(String).ilike('%lead%')
                ])
            elif exp_level == 'middle':
                experience_conditions.extend([
                    User.about.ilike('%middle%'),
                    User.about.ilike('%—Å—Ä–µ–¥–Ω–∏–π%'),
                    User.work_experience.cast(String).ilike('%middle%')
                ])
            elif exp_level == 'junior':
                experience_conditions.extend([
                    User.about.ilike('%junior%'),
                    User.about.ilike('%–Ω–∞—á–∏–Ω–∞—é—â–∏–π%'),
                    User.work_experience.cast(String).ilike('%junior%')
                ])
            
            if experience_conditions:
                query = query.filter(or_(*experience_conditions))

        return query

    def _apply_additional_filters(self, query: Any, additional_keywords: List[str]) -> Any:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã, –µ—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ.
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã –∏ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏.
        """
        if additional_keywords and len(additional_keywords) > 0:
            additional_conditions = []
            for keyword in additional_keywords:
                keyword = keyword.strip()
                if keyword:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –Ω–µ –ø—É—Å—Ç–æ–µ
                    # –ò—â–µ–º –≤ –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã (JSON –ø–æ–ª–µ -> —Ç–µ–∫—Å—Ç)
                    additional_conditions.append(
                        User.work_experience.cast(String).ilike(f'%{keyword}%')
                    )
                    # –ò—â–µ–º –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ (JSON –ø–æ–ª–µ -> —Ç–µ–∫—Å—Ç)
                    additional_conditions.append(
                        User.education.cast(String).ilike(f'%{keyword}%')
                    )
                    # –ò—â–µ–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ "–æ —Å–µ–±–µ" (–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç)
                    additional_conditions.append(
                        User.about.ilike(f'%{keyword}%')
                    )
                    # –ò—â–µ–º –≤ –ø—Ä–æ—á–∏—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è—Ö (JSON –ø–æ–ª–µ -> —Ç–µ–∫—Å—Ç)
                    additional_conditions.append(
                        User.other_competencies.cast(String).ilike(f'%{keyword}%')
                    )
            
            if additional_conditions:
                # –•–æ—Ç—è –±—ã –æ–¥–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–ª–æ–≤–∏–µ –¥–æ–ª–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è
                query = query.filter(or_(*additional_conditions))

        return query

    async def _perform_vector_search(self, db: Session, job_embedding: List[float], 
                                   filtered_users: List[User], limit: int = 20) -> List[Tuple[User, float]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Ä–µ–¥–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.
        –ï—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, —Å–æ–∑–¥–∞–µ—Ç –∏—Ö –Ω–∞ –ª–µ—Ç—É.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –∏—Ö similarity scores.
        """
        user_ids = [user.id for user in filtered_users]
        
        # –ó–∞–ø—Ä–æ—Å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π
        vector_results = db.query(Vec_profile, User).join(User).filter(
            Vec_profile.user_id.in_(user_ids)
        ).all()

        print(f"üîç Found {len(vector_results)} users with existing vector profiles")
        
        candidates_with_similarity = []
        users_with_vectors = set()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª—è–º–∏
        for vec_profile, user in vector_results:
            similarity = self._cosine_similarity(job_embedding, vec_profile.vector)
            candidates_with_similarity.append((user, similarity))
            users_with_vectors.add(user.id)
            print(f"üìä User {user.id} ({user.full_name or user.username}): similarity = {similarity:.3f}")

        # –î–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª–∏ –Ω–∞ –ª–µ—Ç—É
        users_without_vectors = [user for user in filtered_users if user.id not in users_with_vectors]
        
        if users_without_vectors:
            print(f"üîÑ Creating vector profiles for {len(users_without_vectors)} users...")
            for user in users_without_vectors:
                try:
                    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å –Ω–∞ –ª–µ—Ç—É
                    user_profile_text = self._create_user_profile_text(user)
                    user_embedding = await self._call_llm(user_profile_text, is_embedding=True)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å –≤ –±–∞–∑—É
                    vec_profile = Vec_profile(
                        user_id=user.id,
                        vector=user_embedding
                    )
                    db.add(vec_profile)
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º similarity
                    similarity = self._cosine_similarity(job_embedding, user_embedding)
                    candidates_with_similarity.append((user, similarity))
                    print(f"‚úÖ Created vector profile for user {user.id}: similarity = {similarity:.3f}")
                    
                except Exception as e:
                    print(f"‚ùå Failed to create vector profile for user {user.id}: {e}")
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å –±–∞–∑–æ–≤–æ–π –æ—Ü–µ–Ω–∫–æ–π
                    candidates_with_similarity.append((user, 0.5))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
            try:
                db.commit()
                print(f"‚úÖ Saved {len(users_without_vectors)} new vector profiles")
            except Exception as e:
                db.rollback()
                print(f"‚ùå Failed to save vector profiles: {e}")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        candidates_with_similarity.sort(key=lambda x: x[1], reverse=True)
        return candidates_with_similarity[:limit]

    def _create_user_profile_text(self, user: User) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        """
        profile_parts = []
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if user.full_name:
            profile_parts.append(f"–ò–º—è: {user.full_name}")
        
        # –û —Å–µ–±–µ
        if user.about:
            profile_parts.append(f"–û —Å–µ–±–µ: {user.about}")
        
        # –Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        if user.programming_languages:
            languages = ', '.join(user.programming_languages) if isinstance(user.programming_languages, list) else str(user.programming_languages)
            profile_parts.append(f"–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: {languages}")
        
        # –ü—Ä–æ—á–∏–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
        if user.other_competencies:
            competencies = ', '.join(user.other_competencies) if isinstance(user.other_competencies, list) else str(user.other_competencies)
            profile_parts.append(f"–ù–∞–≤—ã–∫–∏ –∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏: {competencies}")
        
        # –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
        if user.work_experience and isinstance(user.work_experience, list):
            for i, exp in enumerate(user.work_experience[:3], 1):  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 –ø–æ–∑–∏—Ü–∏–∏
                if isinstance(exp, dict):
                    role = exp.get('role') or exp.get('position', '')
                    company = exp.get('company', '')
                    responsibilities = exp.get('responsibilities', '')
                    
                    exp_text = f"–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã {i}: {role}"
                    if company:
                        exp_text += f" –≤ {company}"
                    if responsibilities:
                        exp_text += f". –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏: {responsibilities[:200]}..."  # –û–±—Ä–µ–∑–∞–µ–º –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
                    
                    profile_parts.append(exp_text)
        
        # –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        if user.education and isinstance(user.education, list):
            for i, edu in enumerate(user.education[:2], 1):  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2 –∑–∞–ø–∏—Å–∏ –æ–± –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏
                if isinstance(edu, dict):
                    institution = edu.get('institution', '')
                    degree = edu.get('degree', '')
                    field = edu.get('field_of_study', '') or edu.get('specialty', '')
                    
                    edu_text = f"–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ {i}:"
                    if degree:
                        edu_text += f" {degree}"
                    if field:
                        edu_text += f" –ø–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ {field}"
                    if institution:
                        edu_text += f", {institution}"
                    
                    profile_parts.append(edu_text)
        
        # –õ–æ–∫–∞—Ü–∏—è
        if user.location:
            profile_parts.append(f"–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {user.location}")
        
        # –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–µ–∑–¥—É
        if user.ready_to_relocate:
            profile_parts.append("–ì–æ—Ç–æ–≤ –∫ –ø–µ—Ä–µ–µ–∑–¥—É")
        
        # –¢–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏
        if user.employment_type:
            profile_parts.append(f"–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —Ç–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏: {user.employment_type.value}")
        
        # –ñ–µ–ª–∞–µ–º–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞
        if user.desired_salary:
            profile_parts.append(f"–ñ–µ–ª–∞–µ–º–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞: {user.desired_salary}")
        
        # –ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —è–∑—ã–∫–∏
        if user.foreign_languages and isinstance(user.foreign_languages, list):
            languages = []
            for lang in user.foreign_languages:
                if isinstance(lang, dict):
                    lang_name = lang.get('language', '')
                    level = lang.get('level', '')
                    if lang_name:
                        lang_text = lang_name
                        if level:
                            lang_text += f" ({level})"
                        languages.append(lang_text)
            
            if languages:
                profile_parts.append(f"–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —è–∑—ã–∫–∏: {', '.join(languages)}")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –≤ –µ–¥–∏–Ω—ã–π —Ç–µ–∫—Å—Ç
        profile_text = '. '.join(filter(None, profile_parts))
        
        # –ï—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –ø—É—Å—Ç–æ–π, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        if not profile_text.strip():
            profile_text = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.username or user.email}, –ø—Ä–æ—Ñ–∏–ª—å –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω"
        
        return profile_text

    def _cosine_similarity(self, vec1: List[float], vec2) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏
        """
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy arrays –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
            a = np.array(vec1)
            b = np.array(vec2)
            
            # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ = dot(a,b) / (||a|| * ||b||)
            dot_product = np.dot(a, b)
            norm_a = np.linalg.norm(a)
            norm_b = np.linalg.norm(b)
            
            if norm_a == 0 or norm_b == 0:
                return 0.0
            
            similarity = dot_product / (norm_a * norm_b)
            return float(similarity)
        except Exception as e:
            print(f"‚ùå Similarity calculation error: {e}")
            return 0.0

    async def _analyze_candidate_with_ai(self, user: User, job_description: str, 
                                       job_title: str, similarity_score: float) -> CandidateMatch:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM.
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∏ —Å–∞–º–º–∞—Ä–∏.
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        candidate_info = f"""
–ö–ê–ù–î–ò–î–ê–¢:
–ò–º—è: {user.full_name or f"{user.first_name or ''} {user.last_name or ''}".strip() or user.username}
Email: {user.email}
–õ–æ–∫–∞—Ü–∏—è: {user.location or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}
–û —Å–µ–±–µ: {user.about or '–ù–µ —É–∫–∞–∑–∞–Ω–æ'}
–ñ–µ–ª–∞–µ–º–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞: {user.desired_salary or '–ù–µ —É–∫–∞–∑–∞–Ω–∞'}
–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: {', '.join(user.programming_languages or []) or '–ù–µ —É–∫–∞–∑–∞–Ω—ã'}
–ü—Ä–æ—á–∏–µ –Ω–∞–≤—ã–∫–∏: {', '.join(user.other_competencies or []) or '–ù–µ —É–∫–∞–∑–∞–Ω—ã'}
–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã: {len(user.work_experience or []) if user.work_experience else 0} –ø–æ–∑–∏—Ü–∏–π
–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: {len(user.education or []) if user.education else 0} –∑–∞–ø–∏—Å–µ–π
–í–µ–∫—Ç–æ—Ä–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å —Å –≤–∞–∫–∞–Ω—Å–∏–µ–π: {similarity_score:.2f}
        """.strip()

        prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≤–∞–∫–∞–Ω—Å–∏–∏.

–í–ê–ö–ê–ù–°–ò–Ø:
–ù–∞–∑–≤–∞–Ω–∏–µ: {job_title}
–û–ø–∏—Å–∞–Ω–∏–µ: {job_description}

{candidate_info}

–ó–ê–î–ê–ß–ò:
1. –û—Ü–µ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –æ—Ç 0.0 –¥–æ 1.0 (–≥–¥–µ 1.0 - –∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ)
2. –í—ã–¥–µ–ª–∏ 2-3 –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
3. –£–∫–∞–∂–∏ 1-2 –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –Ω–∞–≤—ã–∫–∏
4. –ù–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)

–û–¢–í–ï–¢ –í –§–û–†–ú–ê–¢–ï JSON:
{{
    "match_score": 0.85,
    "strengths": ["–°–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 1", "–°–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 2"],
    "growth_areas": ["–û–±–ª–∞—Å—Ç—å –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è 1", "–û–±–ª–∞—Å—Ç—å –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è 2"],
    "summary": "–ö—Ä–∞—Ç–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –æ–± —ç—Ç–æ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–µ –∏ –µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏"
}}

–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞!
        """

        try:
            ai_response = await self._call_llm(prompt)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_match = re.search(r'\{[\s\S]*\}', ai_response)
            if json_match:
                analysis_data = json.loads(json_match.group())
            else:
                analysis_data = json.loads(ai_response)

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç CandidateMatch
            return CandidateMatch(
                user_id=user.id,
                full_name=user.full_name or f"{user.first_name or ''} {user.last_name or ''}".strip() or user.username,
                email=user.email,
                current_position=self._extract_current_position(user),
                experience_years=self._calculate_experience_years(user),
                key_skills=user.other_competencies or [],
                programming_languages=user.programming_languages or [],
                match_score=analysis_data.get("match_score", 0.5),
                ai_summary=analysis_data.get("summary", "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"),
                strengths=analysis_data.get("strengths", []),
                growth_areas=analysis_data.get("growth_areas", []),
                similarity_score=similarity_score
            )

        except Exception as e:
            print(f"‚ùå AI analysis error for user {user.id}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self._create_fallback_candidate_match(user, similarity_score)

    def _extract_current_position(self, user: User) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—É—â—É—é –ø–æ–∑–∏—Ü–∏—é –∏–∑ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã"""
        if not user.work_experience:
            return None
        
        # –ò—â–µ–º —Ç–µ–∫—É—â—É—é —Ä–∞–±–æ—Ç—É (is_current: true –∏–ª–∏ –Ω–µ—Ç end_date)
        for experience in user.work_experience:
            if isinstance(experience, dict):
                if experience.get('is_current') or not experience.get('period_end'):
                    return experience.get('role') or experience.get('position')
        
        # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é
        if user.work_experience:
            last_exp = user.work_experience[0] if isinstance(user.work_experience[0], dict) else None
            if last_exp:
                return last_exp.get('role') or last_exp.get('position')
        
        return None

    def _calculate_experience_years(self, user: User) -> Optional[str]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–∏–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã –≤ –≥–æ–¥–∞—Ö"""
        if not user.work_experience:
            return None
        
        total_months = 0
        for experience in user.work_experience:
            if isinstance(experience, dict):
                start_date = experience.get('period_start')
                end_date = experience.get('period_end') 
                
                # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞: –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞—Ç—ã, —Å—á–∏—Ç–∞–µ–º —Ä–∞–∑–Ω–æ—Å—Ç—å
                if start_date and end_date:
                    try:
                        # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
                        total_months += 12  # –ó–∞–≥–ª—É—à–∫–∞: —Å—á–∏—Ç–∞–µ–º –≥–æ–¥ –∑–∞ –∫–∞–∂–¥—É—é –ø–æ–∑–∏—Ü–∏—é
                    except:
                        pass
        
        if total_months > 0:
            years = total_months // 12
            return f"{years} –ª–µ—Ç" if years > 1 else f"{total_months} –º–µ—Å."
        
        return "–û–ø—ã—Ç –Ω–µ —É–∫–∞–∑–∞–Ω"

    def _create_fallback_candidate_match(self, user: User, similarity_score: float) -> CandidateMatch:
        """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ AI"""
        base_score = min(0.8, similarity_score + 0.2) if similarity_score > 0.5 else similarity_score
        
        return CandidateMatch(
            user_id=user.id,
            full_name=user.full_name or f"{user.first_name or ''} {user.last_name or ''}".strip() or user.username,
            email=user.email,
            current_position=self._extract_current_position(user),
            experience_years=self._calculate_experience_years(user),
            key_skills=user.other_competencies or [],
            programming_languages=user.programming_languages or [],
            match_score=round(base_score, 2),
            ai_summary="–ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –ø—Ä–æ—Ñ–∏–ª—è",
            strengths=["–ï—Å—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ–ø—ã—Ç"] if similarity_score > 0.6 else [],
            growth_areas=["–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"],
            similarity_score=similarity_score
        )

    async def search_candidates(self, db: Session, request: CandidateSearchRequest) -> CandidateSearchResponse:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.
        –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è -> –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ -> AI –∞–Ω–∞–ª–∏–∑
        """
        start_time = time.time()
        applied_filters = []

        print(f"üîç Starting candidate search for: {request.job_title}")
        
        # –®–∞–≥ 1: –ü—Ä–∏–º–µ–Ω—è–µ–º –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        print("üìã Applying basic filters...")
        base_query = self._apply_basic_filters(db, request.required_skills, request.experience_level)
        base_candidates = base_query.all()
        
        if request.required_skills:
            applied_filters.append(f"Skills: {', '.join(request.required_skills)}")
        if request.experience_level:
            applied_filters.append(f"Experience: {request.experience_level}")
        
        print(f"üìä Found {len(base_candidates)} candidates after basic filtering")

        # –®–∞–≥ 2: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        filtered_candidates = base_candidates
        if len(base_candidates) > request.threshold_filter_limit:
            print(f"‚ö° Too many candidates ({len(base_candidates)}), applying additional filters...")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏
            additional_keywords = self._extract_key_terms(request.job_description)
            additional_query = self._apply_additional_filters(base_query, additional_keywords)
            filtered_candidates = additional_query.all()
            
            applied_filters.append(f"Additional keywords: {', '.join(additional_keywords[:3])}")
            print(f"üìä After additional filtering: {len(filtered_candidates)} candidates")

        # –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        print("üß† Generating job embedding...")
        job_embedding = await self._generate_job_embedding(request.job_description, request.job_title)

        # –®–∞–≥ 4: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Ä–µ–¥–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤  
        print("üîé Performing vector similarity search...")
        candidates_with_similarity = await self._perform_vector_search(
            db, job_embedding, filtered_candidates, request.max_candidates
        )

        # –®–∞–≥ 5: AI-–∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        print(f"ü§ñ Analyzing {len(candidates_with_similarity)} candidates with AI...")
        analyzed_candidates = []
        
        for user, similarity in candidates_with_similarity:
            try:
                candidate_match = await self._analyze_candidate_with_ai(
                    user, request.job_description, request.job_title, similarity
                )
                analyzed_candidates.append(candidate_match)
            except Exception as e:
                print(f"‚ùå Failed to analyze candidate {user.id}: {e}")
                # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
                fallback_match = self._create_fallback_candidate_match(user, similarity)
                analyzed_candidates.append(fallback_match)

        # –®–∞–≥ 6: –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ AI
        analyzed_candidates.sort(key=lambda x: x.match_score, reverse=True)

        processing_time = time.time() - start_time
        print(f"‚úÖ Search completed in {processing_time:.2f}s")

        return CandidateSearchResponse(
            job_title=request.job_title,
            total_profiles_found=len(filtered_candidates),
            processed_by_ai=len(analyzed_candidates),
            filters_applied=applied_filters,
            candidates=analyzed_candidates,
            processing_time_seconds=round(processing_time, 2)
        )

    def _extract_key_terms(self, text: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        """
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        key_terms = []
        
        # –û–±—â–∏–µ IT —Ç–µ—Ä–º–∏–Ω—ã
        it_terms = [
            'backend', 'frontend', 'fullstack', 'devops', 'qa', 'analyst', 'manager',
            'mobile', 'web', 'api', 'database', 'cloud', 'docker', 'kubernetes',
            'agile', 'scrum', 'team lead', 'architect', 'senior', 'middle', 'junior'
        ]
        
        text_lower = text.lower()
        for term in it_terms:
            if term in text_lower:
                key_terms.append(term)
        
        return key_terms[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
_hr_search_service = None

def get_hr_candidate_search_service() -> HRCandidateSearchService:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞ –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"""
    global _hr_search_service
    if _hr_search_service is None:
        _hr_search_service = HRCandidateSearchService()
    return _hr_search_service
